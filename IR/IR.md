IR50问
======


1.什么是ad-hoc检索
------------------

**答：**任意用户的信息需求是一次性的、由用户提交的查询传递给系统，系统从文档即中返回与之相关的文档。简而言之，就是我们现在的百度、谷歌这样的。

2.倒排索引建立的基本步骤什么？
----------------------------

**答：**

* 收集文档，可以理解为爬虫爬网页，或者其他什么的
* 词条化(tokenization)，简单的理解可以为，把什么样的字符串判断为一个词，对于汉语来说，还要有分词的过程，对于英语来说，像I'm 这样的词，应该判断为I am 好，还是I m 好，还是I好，还是其他的
* 进行语言学处理，即stem等去除文档后缀的工作
* 建立倒排索引

3.倒排索引应该存储什么额外信息？
------------------------------

**答：**

* 最基本的倒排索引只需要存储每个词都在哪个文章中出现过，即word1->doc1,doc2 word2->doc3,doc4
* 为了方便使用，倒排索引一般还会在每个词的头部加入后面文章的数量，方便遍历
* 为了能够检测出连贯词，如Stanford University等，还应该加入每个词在该文章中的位置信息
* 为了进行向量空间匹配，即比较常用的Okapi BM25等，还应该加入idf信息，需要指出的是idf = N/df，即知道文章数量后就可以知道了，但是为了节省时间，可以直接算出
* 同样的，每篇文章应该存储该词的tf信息，tf就是词频
* 如果需要快速访问，倒排索引可能还会加入skip list结构，这样的话，需要存储跳表的索引 

**我不知道自己总结的全不全**

4.stemming和lemmatization有什么区别
-------------------------------

**答：**

* stem是主干化的意思，也可以认为就是将词前后缀去掉，比如car，cars，car's，cars' ==> car
* lemmatization是词形归并，也就是例如：am，is，are ==> be

通常来说lemmatization对检索提高的幅度极其有限，而且这两种方法也不会显著提高检索的性能，会增加很多检索正确，但是同样也会检索错很多。

5.如何提高倒排索引的检索速度
--------------------------

**答：**

一种比较常用的方法是添加**跳表(skip list)**，即在每个词的倒排索引上加一个索引，记录每5个(例如)文档的位置。例如：

	word --> 1,2,3,4,5,6,7,8,9,10,......

我们每个三个词记录其位置，对于上面的例子，记录1，4，7，10... 的例子，对于每次合并的时候进行快速跳跃，这样可以比较多的提升倒排索引的合并速度。

对于跳表设立索引的位置，可以每个sqrt(p)个文章设立一个索引，p是倒排索引的长度。

这里需要注意的是，跳表主要处理的是and的情况，不能处理or的情况。

6.如何查询多元词
--------------

**答：**

这里说一下，多元词，这个名词是我自己说的，比较标准的说法是，含有位置信息的词。在很多查询中，我们想查"Stanford University"，但是我们并不希望句子"The inventor Stanford never went to the university"。

我们希望查询的是短语，希望两个词连贯，或者比较临近(这也是有可能发生的)。

一种解决方式是我们在建立倒排索引的时候建立二元连续词对的索引(biword)。例如查询"哈工大教务处系统"，可进行如下查询：

	"哈工大教务处" AND "教务处系统"

当然，这里在查询的时候也会规避掉一些虚词，这点很重要，因为虚词很没有用处。我们可以先对句子进行词性标注(POS)。然后只选出实词进行检索。

这种短语检索的方式最大的缺点就是会大大增加词表的长度。

还有一种解决方式就是记录索引的位置信息，在倒排索引中记录每个词在该文章的所有位置，然后进行匹配。这样，只需在合并倒排索引的时候同时检查词的位置信息即可，缺点是会大大增加倒排索引的大小，但是现代搜索引擎具体需要的问题，这种做法基本上是通用做法。

总结一下，可以对比较高频查询的词进行短语查询，而对一般需求进行基于位置的查询。

还有一种比较新的解决方法是，在倒排索引中加入该词下一个词。虽然会比基于位置的索引方法增加26%的空间，但是搜索时间只有基于位置信息方式的25%。

7.词典建立的方式有哪些种
------------------------

**答：**

主要有两大类：基于哈希的方式，基于搜索树的方式

在选择具体用哪种方案时，要考虑以下问题：

* 键的数目有多少
* 键的数目是否固定，需不需要删除
* 不同键的对应访问频率

哈希将每个词映射成一个整数，映射函数要足够大，以减少冲突的可能。这种方式的缺点是，无法处理词有轻微变形的情况。例如naive有两个版本。也很难解决拼写纠错等问题，在Web环境下，由于词表总是增长的，当前的哈希函数有可能在几年以后失效。

基于树的方式就要对这类问题好很多，比较著名的有trie树，B树等。


8.如何进行通配符查询
------------------

**答：**

下面说的是基于搜索树的解决方式。

最简单的情况莫过于查询moon*，即前缀为moon的情况。解决方法是搜索树，返回moon以后的所有节点。

更为复杂的情况是*moon，即后缀为moon的情况，这里我们可以反方向建立一个搜索树，即例如work，我们建立搜索树的方式是k--->r--->o--->w，然后倒着查一遍。

对于更一般的情况。我们可以用轮排表来实现，例如hello，我们建立的方式如下：

	hello$ , ello$h , llo$he , ......

$标志词结束。

对于查询m\*n，我们可以转化为查询m\*n$，进而转化为n$m\*，然后进行前缀查询。

最为复杂的情况莫过于查询fi\*mo\*er，我们可以先查询er$fi\*进行前缀式查询，然后过滤掉不满意的词，但这种方式开销比较大。

也可以不用轮排表而利用k-gram的方式解决，这里就不介绍了。


9.如何进行拼写校正
------------------

**答：**

对于大多数拼写校正来说，有以下两个基本原则。
* 对于一个拼写错误的查询，在其可能的结果中，选择距离最近的一个
* 当两个距离相近或者相等时，选择更为常见的一个。

比较常见的拼写校正的方法有两种，分为词项独立和上下文敏感的。

词项独立的方法主要依靠编辑距离这种，这里就不介绍了。

对于上下文敏感的算法，例如flew from Peking，即使每个单词拼写都对，当检索结果非常低的时候，我们也对其进行替换，尝试可能的词组，返回查询结果中比较高的。一些启发式的方法可以减少搜索空间。

10.tf-idf
---------------------

**答：**

* tf是词频率，即在该篇文章中出现了几次，则记为几
* df是文档频率，即词在多少篇文章中出现过，则即为几
* idf是逆文档频率，表示为log(N/df)，N为文档数

tf主要可以用两种，一种为tf，一种为亚线性tf，即取log(tf)，这样可以部分减弱高频词的影响。


